# История разработки KotvukAI

Данный документ описывает процесс разработки платформы KotvukAI поэтапно — от первоначального анализа предметной области до финального деплоя с полным мониторингом.

---

## Этап 1. Анализ предметной области и постановка задачи

Разработка началась с глубокого изучения рынка криптовалютной аналитики. Были проанализированы ведущие платформы: TradingView (профессиональные графики, но платный доступ к индикаторам), CoinGecko (агрегатор данных без трейдинговых инструментов), Binance Web (функционально, но перегружен), Coinigy и Cryptowatch. Главный вывод: ни одна из платформ не совмещает технический анализ, AI-ассистента и обучающие материалы в едином интерфейсе, доступном бесплатно.

На основе анализа была определена целевая аудитория: начинающие и средние трейдеры, которым нужен один инструмент вместо набора разрозненных сервисов. Составлен список must-have функций: графики с индикаторами, AI анализ, отслеживание сделок, алерты, новости, обучение. Функции разделены на три уровня: Free (базовый доступ), Pro (расширенные лимиты), Premium (без ограничений).

Параллельно был проведён анализ технических требований: real-time данные требуют WebSocket, AI интеграция требует API к языковой модели, мобильная доступность — PWA. Всё это сформировало архитектурные ограничения ещё до написания первой строки кода.

---

## Этап 2. Проектирование архитектуры и выбор стека

Выбор фронтенд-фреймворка: React 18 выбран над Next.js, поскольку проект является SPA (Single Page Application) без требований к SSR и SEO. Vite 5 как сборщик — значительно быстрее CRA (Create React App), горячая замена модулей работает мгновенно.

Выбор базы данных: SQLite (через better-sqlite3) выбран над PostgreSQL осознанно для дипломного проекта. SQLite не требует отдельного сервера, работает из коробки, файл БД легко переносить, а WAL (Write-Ahead Logging) режим обеспечивает конкурентное чтение. Для production-масштабирования предусмотрена миграция на PostgreSQL — архитектура на это рассчитана.

Схема БД спроектирована как 8 таблиц: `users` (аккаунты с планами), `trades` (сделки с привязкой к пользователю), `alerts` (ценовые алерты), `watchlist` (избранные пары), `signals` (AI сигналы), `signal_results` (результаты сигналов для self-learning), `plans` (конфигурация тарифных планов), `settings` (глобальные настройки платформы). Связи между таблицами через foreign keys с каскадным удалением.

Express.js выбран над Fastify из-за более широкой экосистемы и знакомого синтаксиса. Архитектура разделена на три слоя: routes (HTTP обработчики), services (бизнес-логика), utils (вспомогательные функции). Это обеспечивает тестируемость: `server.js` только запускает сервер, `app.js` содержит Express конфигурацию — тесты импортируют `app.js` напрямую без запуска HTTP сервера.

---

## Этап 3. Разработка схемы БД и backend-фундамента

Первым делом реализована система аутентификации. Выбрана JWT-схема с двумя токенами: access token (24 часа) и refresh token (30 дней). Разные секреты для обоих токенов (`JWT_SECRET` и `JWT_REFRESH_SECRET`) и проверка типа (`payload.type !== 'refresh'`) предотвращают подстановку refresh token вместо access token. Пароли хешируются bcrypt с коэффициентом работы 12 (баланс между безопасностью и производительностью — ~300ms на хеширование).

Реализована миграционная поддержка: при входе старых пользователей с SHA-256 хешами (legacy) система автоматически перехеширует пароль в bcrypt без какого-либо участия пользователя. Функция `needsRehash()` проверяет наличие префикса `$2b$` или `$2a$`.

Middleware архитектура строится по принципу "мягкой" аутентификации: `authMiddleware` всегда вызывает `next()`, просто устанавливая или не устанавливая `req.user`. Это позволяет некоторым роутам работать и для анонимных, и для авторизованных пользователей. Когда нужна жёсткая проверка — добавляется `requireAuth` или `requireAdmin` как дополнительный guard.

Система миграций реализована через `try { db.exec('ALTER TABLE...') } catch(e) {}` — при каждом запуске сервер пробует добавить новые колонки, молча пропуская если они уже есть. Это простой, но рабочий подход для учебного проекта.

---

## Этап 4. Реализация алгоритмов технического анализа

Технический анализ реализован полностью с нуля в `backend/services/indicators.js` без использования внешних библиотек — это принципиальное решение, демонстрирующее понимание алгоритмов.

**EMA (Exponential Moving Average)** — экспоненциальное скользящее среднее. Используется множитель сглаживания `k = 2 / (period + 1)`. Первое значение берётся как SMA (среднее первых N свечей), каждое последующее: `EMA = price * k + EMA_prev * (1 - k)`. Реализованы отдельно `computeEMA` (одно значение) и `computeEMASeries` (массив для отрисовки на графике).

**RSI (Relative Strength Index)** — индекс относительной силы по методу Wilder (не Simple Moving Average). Первый RSI считается через простое среднее gains/losses за 14 периодов, далее используется сглаживание Wilder: `avg_gain = (prev_avg_gain * 13 + current_gain) / 14`. Формула: `RSI = 100 - 100 / (1 + RS)` где `RS = avg_gain / avg_loss`. Использование сглаживания Wilder (а не SMA) — ключевое отличие правильной реализации RSI от упрощённой.

**MACD (Moving Average Convergence Divergence)** — разность двух EMA (12 и 26 периодов). Signal line — EMA(9) от MACD. Гистограмма — разность MACD и signal. Реализован полный набор: `computeMACD` (текущие значения) и `computeMACDSeries` (история для графика).

**Bollinger Bands** — полосы волатильности. Средняя полоса — SMA(20). Верхняя и нижняя — средняя ± (2 × стандартное отклонение). Используется population std (не sample), что является стандартной практикой для скользящих окон фиксированного размера.

---

## Этап 5. Разработка REST API и внешние интеграции

Разработано 15 Express роутов, каждый в отдельном файле. Основные интеграции:

**Binance API** — прокси для рыночных данных: свечи (klines), 24h статистика, order book (level2), последние сделки. Добавлено in-memory кэширование: ticker24h кэшируется 10 секунд, heatmap данные — 30 секунд, одиночные тикеры — 5 секунд. Без кэша N пользователей = N параллельных запросов к Binance, что приводит к rate limiting со стороны биржи.

**Groq API** (LLaMA 3) — AI анализ и чат. Для анализа используется многотаймфреймовый подход: запрашиваются данные по 6 таймфреймам (1m, 5m, 15m, 1h, 4h, 1d), вычисляются индикаторы для каждого, добавляется контекст BTC (корреляция рынка), Fear & Greed индекс. Всё это формирует prompt для Groq. Из ответа regex-парсингом извлекаются TP, SL, direction, confidence — для сохранения в БД и последующего трекинга.

**CryptoCompare** — агрегатор новостей. До 30 последних новостей с заголовками, описаниями, источниками. Отдельный endpoint `/api/news/summary` принимает заголовок+тело новости, отправляет в Groq для AI-краткого содержания на выбранном языке (RU/EN).

**Glassnode** — on-chain метрики. Active Addresses, Hash Rate, NVT Ratio, MVRV, SOPR, Exchange Inflow/Outflow. Данные кэшируются 5 минут (изменяются редко). При недоступности API — возвращается ошибка с понятным сообщением, mock данные не используются.

Для защиты AI endpoints разработан `middleware/rateLimit.js` с дифференцированными лимитами по планам: Free (5 запросов/день), Pro (50), Premium (без ограничений).

---

## Этап 6. WebSocket и real-time архитектура

Real-time ценовые данные реализованы через двойной WebSocket: внешний (подключение к Binance Stream) и внутренний (раздача данных клиентам браузера).

**Binance Stream**: подключение к `wss://stream.binance.com:9443/stream?streams=btcusdt@ticker/ethusdt@ticker/...` для 10 основных пар. При разрыве соединения — автопереподключение через 5 секунд с очисткой предыдущего таймера. При получении данных — парсинг и обновление локального `prices` Map.

**Клиентский broadcast**: при подключении нового клиента сразу отправляется snapshot текущих цен (`type: 'snapshot'`), чтобы не ждать следующего тика от Binance. При каждом обновлении цены — рассылка всем подключённым клиентам (`type: 'price'`).

**Frontend hook** (`useWebSocket.js`): React hook с reconnect (3 секунды), cleanup при unmount. Возвращает объект `prices` — Map из символа в {price, change}. Используется в DashboardPanel для живого тикера.

Архитектурное решение — сервер держит одно соединение с Binance и раздаёт данные N клиентам. Это значительно эффективнее, чем каждый клиент подключается к Binance напрямую (Binance ограничивает количество соединений с одного IP).

---

## Этап 7. Разработка фронтенда: базовые компоненты

Архитектура фронтенда строится на трёх React Context провайдерах, которые оборачивают всё приложение в правильном порядке: `ThemeProvider → LangProvider → AuthProvider → App`.

**ThemeContext** — полная цветовая система с 25+ токенами для dark и light темы (cardBg, border, text, textSecondary, textMuted, accent, inputBg, blueBg, red, redBg, tableBorder и др.). Тема сохраняется в localStorage, применяется мгновенно без перезагрузки.

**LangContext** — i18n система. Файл `i18n.js` содержит ~400 строк переводов для RU и EN. Функция `t(key)` возвращает перевод с fallback на ключ если перевод не найден. Язык переключается в runtime без перезагрузки.

**AuthContext** — управление сессией. При инициализации проверяет localStorage на наличие токена, валидирует через `/api/auth/me`. Реализован `authFetch` — обёртка над fetch с автоматическим обновлением access token при получении 401: вызывает `/api/auth/refresh` с refresh token, сохраняет новый access token, повторяет исходный запрос. При неудаче — разлогинивает.

Routing реализован без react-router: состояние `activePanel` в App.jsx, рендеринг нужного компонента через объект-маппинг. Для анимаций переходов — `AnimatePresence` + `motion.div` из Framer Motion с fade+slide эффектом.

---

## Этап 8. Разработка 15 панелей интерфейса

**Charts Panel** — наиболее сложный компонент. TradingView Lightweight Charts для рендеринга candlestick/line/area графиков. 10 торговых пар, 7 таймфреймов. Инструменты рисования: горизонтальная линия (поддержка/сопротивление), трендлиния (два клика), уровни Fibonacci (23.6%, 38.2%, 50%, 61.8%, 78.6%). Рисунки сохраняются в localStorage по ключу `drawings_BTCUSDT_1h`. Индикаторы (EMA, RSI, MACD, Bollinger) вычисляются на клиенте из загруженных данных.

**AI Panel** — выбор из 40+ активов с live поиском (useMemo для фильтрации). Запрос анализа уходит на бэкенд, возвращается структурированный результат: направление (LONG/SHORT), confidence (0-100%), TP/SL, текстовое обоснование. Визуализация: цветной badge уверенности, SVG circle с coin score, прогресс-бары по индикаторам. История последних 10 сигналов по активу. Лимит использования (5/день Free) с модальным окном при превышении.

**Screener Panel** — таблица 50+ пар с сортировкой по любой колонке, фильтром по % изменению, поиском. Мини-sparkline SVG без библиотек для визуализации тренда. `useMemo` для сортировки и фильтрации без лишних ре-рендеров.

**Whale Panel** — визуализация order book: bids и asks с прогресс-барами пропорционально объёму, соотношение buy/sell в процентах. Лента крупных сделок (>$100k) с цветовым кодированием (зелёный = buy, красный = sell). Автообновление каждые 15 секунд.

**Calculator Panel** — калькулятор позиции: депозит, процент риска, плечо, точки входа/SL/TP. Результат — рекомендуемый размер позиции, максимальный убыток в $ и %. Оригинальный `RiskGauge` — SVG полукруг с анимированной иглой, показывающей уровень риска от зелёного (низкий) до красного (критический).

---

## Этап 9. Self-learning AI сигнальная система

Ключевая оригинальная разработка проекта — система самообучения AI сигналов. Архитектура реализует петлю обратной связи из четырёх фаз.

**Фаза 1 — Генерация сигнала**: пользователь запрашивает AI анализ актива. Система делает многотаймфреймовый анализ (6 TF), формирует структурированный prompt с техническими индикаторами, текущей ценой, BTC корреляцией. Groq возвращает прогноз с direction/TP/SL/confidence. Сигнал сохраняется в таблицу `signals` со статусом `active`.

**Фаза 2 — Трекинг цены**: `signalChecker.js` запускается каждые 60 секунд. Для каждого активного сигнала запрашивает текущую цену с Binance. Проверяет достижение TP или SL. При истечении 24 часов без достижения — статус `timeout`.

**Фаза 3 — Автоматическая резолюция**: при достижении TP статус меняется на `tp_hit` (успешный сигнал), при достижении SL — `sl_hit` (неудачный). Результат сохраняется в `signal_results` с точной ценой выхода и временем.

**Фаза 4 — AI рефлексия**: после каждой резолюции система отправляет в Groq запрос на рефлексию: "Сигнал LONG по BTCUSDT оказался [успешным/неудачным]. TP достигнут за 4 часа. Что можно улучшить в анализе?". Ответ сохраняется и включается как дополнительный контекст при следующих запросах анализа того же актива. Это даёт модели "память" о предыдущих прогнозах.

---

## Этап 10. PWA, экспорт и дополнительные возможности

**PWA (Progressive Web App)**: реализован `service-worker.js` со стратегией cache-first для статических ресурсов (JS, CSS, иконки) и network-first для API запросов (актуальные данные важнее кэша). При установке — кэшируются ключевые статические файлы. При активации — удаляются старые версии кэша. Поддержка `SKIP_WAITING` для немедленного обновления при выходе новой версии.

**PDF экспорт**: бэкенд генерирует PDF через PDFKit. Таблица сделок с форматированием: чередующиеся строки, зелёный/красный цвет для прибыльных/убыточных позиций, итоговая статистика (Total PnL, Win Rate, количество сделок). Клиент скачивает через blob URL без промежуточного сохранения на сервере.

**Аудио-алерты**: при срабатывании ценового алерта проигрывается звуковой сигнал через Web Audio API — без зависимостей, нативно. `beep()` функция создаёт OscillatorNode, устанавливает частоту (880Hz), длительность (200ms), с try/catch для совместимости с Safari. Отслеживание уже воспроизведённых алертов через `useRef` — без лишних ре-рендеров.

**Prometheus метрики**: `middleware/metrics.js` собирает HTTP request counter (метод, роут, статус), histogram задержек (9 buckets от 5ms до 5000ms), default Node.js метрики (heap, CPU, event loop lag). Endpoint `/metrics` защищён через `requireAdmin` — только администратор может просматривать метрики в Prometheus формате.

---

## Этап 11. Тестирование и обеспечение безопасности

**Backend тесты** (Jest + Supertest): 11 тестовых файлов, 130+ тест-кейсов. Каждый тест работает с изолированной SQLite базой (уникальное имя через PID + timestamp). `tests/setup.js` предоставляет хелпер `createTestUser()` и глобальный mock для fetch (блокирует внешние HTTP запросы в тестах). Покрытие: аутентификация (JWT roundtrip, tamper detection, refresh flow), индикаторы (edge cases: пустые данные, монотонный рост, flat data), trades (PnL расчёты для long/short), alerts (логика триггеров), admin (RBAC, защита от самоудаления), signals (полный lifecycle), экспорт (Content-Type).

**Frontend тесты** (Vitest + Testing Library): AuthContext (начальное состояние, загрузка из токена, очистка при expired), App (рендер landing page без аутентификации), WebSocket логика (URL формат, парсинг сообщений).

**Безопасность**: пароли bcrypt с rounds=12; rate limiting на login (5 попыток/15 минут по IP с автосбросом); whitelist из 44 разрешённых символов в AI endpoint (защита от HTTP parameter injection в Binance URL); CORS настроен на конкретные origins; JWT access tokens короткоживущие (24h), refresh tokens долгоживущие (30d) с type check; admin endpoints защищены `requireAdmin` middleware; Snyk сканирование зависимостей в CI.

---

## Этап 12. DevOps, деплой и мониторинг

**CI/CD через GitHub Actions**: два pipeline — `ci.yml` (на каждый push/PR) и `deploy.yml` (на push в main). CI выполняет: установку зависимостей, ESLint проверку, запуск всех тестов, сборку фронтенда, Snyk сканирование на уязвимости. Deploy выполняет SSH подключение к серверу, git pull, npm ci, vite build, pm2 restart.

**Kubernetes**: манифесты для production деплоя. `deployment.yml` — 1 реплика (SQLite ограничение), resource limits (CPU: 250m-500m, Memory: 256Mi-512Mi), liveness probe (`GET /health` каждые 30s), readiness probe (каждые 10s). `service.yml` — ClusterIP сервис. `secrets.yml` — шаблон для хранения JWT секретов и API ключей через Kubernetes Secrets (не в образе). Переменные окружения инжектируются через `secretKeyRef`.

**Prometheus + Grafana**: `docker-compose.monitoring.yml` поднимает Prometheus (30-дневное хранение метрик, scrape каждые 10s) и Grafana. Метрики: RPS, задержки (p50/p95/p99), error rate, Node.js heap usage, event loop lag.

**ELK стек**: Elasticsearch + Logstash + Kibana через `docker-compose.elk.yml`. Logstash слушает TCP/UDP 5000, принимает JSON логи от Winston, добавляет теги (severity, app: kotvukai), парсит timestamp, отправляет в Elasticsearch с индексом `kotvukai-logs-YYYY.MM.DD`. Kibana для визуализации и поиска по логам.

**Velero backup**: ежедневный backup Kubernetes ресурсов в 02:00 UTC, TTL 720 часов (30 дней). Включает deployments, services, secrets, configmaps, PVC с snapshot volumes. Обеспечивает возможность восстановления кластера после катастрофических сбоев.
